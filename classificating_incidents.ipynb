{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "518ee011",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VINOTH\\AppData\\Local\\Temp\\ipykernel_14612\\2694159657.py:3: DtypeWarning: Columns (10,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"C:\\\\Users\\\\VINOTH\\\\Downloads\\\\GUIDE_Test.csv\\\\GUIDE_Test.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Id  OrgId  IncidentId  AlertId                 Timestamp  \\\n",
      "0        1245540519230    657       11767    87199  2024-06-04T22:56:27.000Z   \n",
      "1        1400159342154      3       91158   632273  2024-06-03T12:58:26.000Z   \n",
      "2        1279900255923    145       32247   131719  2024-06-08T03:20:49.000Z   \n",
      "3          60129547292    222       15294   917686  2024-06-12T12:07:31.000Z   \n",
      "4         515396080539    363        7615     5944  2024-06-06T17:42:05.000Z   \n",
      "...                ...    ...         ...      ...                       ...   \n",
      "4147987   541165881145    262        3017   227156  2024-06-04T03:53:15.000Z   \n",
      "4147988   438086666953   1323       31001   304819  2024-06-04T19:32:19.000Z   \n",
      "4147989  1297080124487     47        3653     7243  2024-06-15T00:50:22.000Z   \n",
      "4147990   627065226886     70        4243    19142  2024-06-11T16:18:12.000Z   \n",
      "4147991   326417516547    227        8384    33529  2024-06-04T18:11:09.000Z   \n",
      "\n",
      "         DetectorId  AlertTitle           Category  \\\n",
      "0               524         563    LateralMovement   \n",
      "1                 2           2  CommandAndControl   \n",
      "2              2932       10807    LateralMovement   \n",
      "3                 0           0      InitialAccess   \n",
      "4                27          18          Discovery   \n",
      "...             ...         ...                ...   \n",
      "4147987         139         120      InitialAccess   \n",
      "4147988         219         196      InitialAccess   \n",
      "4147989          57          29  CommandAndControl   \n",
      "4147990           1           1      InitialAccess   \n",
      "4147991           1           1      InitialAccess   \n",
      "\n",
      "                         MitreTechniques   IncidentGrade  ...       Roles  \\\n",
      "0            T1021;T1047;T1105;T1569.002  BenignPositive  ...         NaN   \n",
      "1                                    NaN  BenignPositive  ...         NaN   \n",
      "2        T1021;T1027.002;T1027.005;T1105  BenignPositive  ...         NaN   \n",
      "3                        T1078;T1078.004   FalsePositive  ...         NaN   \n",
      "4                        T1087;T1087.002  BenignPositive  ...  Suspicious   \n",
      "...                                  ...             ...  ...         ...   \n",
      "4147987                        T1566.002  BenignPositive  ...         NaN   \n",
      "4147988                              NaN  BenignPositive  ...         NaN   \n",
      "4147989                T1046;T1071;T1210   FalsePositive  ...         NaN   \n",
      "4147990                        T1566.002  BenignPositive  ...         NaN   \n",
      "4147991                        T1566.002    TruePositive  ...         NaN   \n",
      "\n",
      "        OSFamily OSVersion AntispamDirection  SuspicionLevel     LastVerdict  \\\n",
      "0              5        66               NaN      Suspicious      Suspicious   \n",
      "1              0         0               NaN      Suspicious      Suspicious   \n",
      "2              5        66               NaN      Suspicious      Suspicious   \n",
      "3              5        66               NaN             NaN             NaN   \n",
      "4              5        66               NaN             NaN             NaN   \n",
      "...          ...       ...               ...             ...             ...   \n",
      "4147987        5        66               NaN             NaN             NaN   \n",
      "4147988        5        66               NaN             NaN             NaN   \n",
      "4147989        5        66               NaN             NaN             NaN   \n",
      "4147990        5        66               NaN             NaN             NaN   \n",
      "4147991        5        66               NaN             NaN  NoThreatsFound   \n",
      "\n",
      "         CountryCode  State   City    Usage  \n",
      "0                242   1445  10630  Private  \n",
      "1                242   1445  10630   Public  \n",
      "2                242   1445  10630   Public  \n",
      "3                242   1445  10630   Public  \n",
      "4                242   1445  10630   Public  \n",
      "...              ...    ...    ...      ...  \n",
      "4147987          242   1445  10630   Public  \n",
      "4147988          242   1445  10630  Private  \n",
      "4147989          242   1445  10630   Public  \n",
      "4147990          242   1445  10630  Private  \n",
      "4147991          242   1445  10630   Public  \n",
      "\n",
      "[4147992 rows x 46 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\VINOTH\\\\Downloads\\\\GUIDE_Test.csv\\\\GUIDE_Test.csv\")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64a64622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                          0\n",
       "OrgId                       0\n",
       "IncidentId                  0\n",
       "AlertId                     0\n",
       "Timestamp                   0\n",
       "DetectorId                  0\n",
       "AlertTitle                  0\n",
       "Category                    0\n",
       "MitreTechniques       2307104\n",
       "IncidentGrade               0\n",
       "ActionGrouped         4146079\n",
       "ActionGranular        4146079\n",
       "EntityType                  0\n",
       "EvidenceRole                0\n",
       "DeviceId                    0\n",
       "Sha256                      0\n",
       "IpAddress                   0\n",
       "Url                         0\n",
       "AccountSid                  0\n",
       "AccountUpn                  0\n",
       "AccountObjectId             0\n",
       "AccountName                 0\n",
       "DeviceName                  0\n",
       "NetworkMessageId            0\n",
       "EmailClusterId        4106285\n",
       "RegistryKey                 0\n",
       "RegistryValueName           0\n",
       "RegistryValueData           0\n",
       "ApplicationId               0\n",
       "ApplicationName             0\n",
       "OAuthApplicationId          0\n",
       "ThreatFamily          4116614\n",
       "FileName                    0\n",
       "FolderPath                  0\n",
       "ResourceIdName              0\n",
       "ResourceType          4144998\n",
       "Roles                 4039317\n",
       "OSFamily                    0\n",
       "OSVersion                   0\n",
       "AntispamDirection     4071481\n",
       "SuspicionLevel        3498157\n",
       "LastVerdict           3155260\n",
       "CountryCode                 0\n",
       "State                       0\n",
       "City                        0\n",
       "Usage                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73ed99d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()\n",
    "df.dropna(thresh=0.9 * len(df), axis=1, inplace=True)  # drop columns with >90% NaNs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "743b00a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                    0\n",
       "OrgId                 0\n",
       "IncidentId            0\n",
       "AlertId               0\n",
       "Timestamp             0\n",
       "DetectorId            0\n",
       "AlertTitle            0\n",
       "Category              0\n",
       "IncidentGrade         0\n",
       "EntityType            0\n",
       "EvidenceRole          0\n",
       "DeviceId              0\n",
       "Sha256                0\n",
       "IpAddress             0\n",
       "Url                   0\n",
       "AccountSid            0\n",
       "AccountUpn            0\n",
       "AccountObjectId       0\n",
       "AccountName           0\n",
       "DeviceName            0\n",
       "NetworkMessageId      0\n",
       "RegistryKey           0\n",
       "RegistryValueName     0\n",
       "RegistryValueData     0\n",
       "ApplicationId         0\n",
       "ApplicationName       0\n",
       "OAuthApplicationId    0\n",
       "FileName              0\n",
       "FolderPath            0\n",
       "ResourceIdName        0\n",
       "OSFamily              0\n",
       "OSVersion             0\n",
       "CountryCode           0\n",
       "State                 0\n",
       "City                  0\n",
       "Usage                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54e7600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Timestamp', 'Category', 'IncidentGrade', 'EntityType', 'EvidenceRole', 'Usage']\n"
     ]
    }
   ],
   "source": [
    "categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "print(categorical_cols)\n",
    "#df.drop(Usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78c9acaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "with open('label_encoder.pkl', 'rb') as f:\n",
    "    loaded_encoder = pickle.load(f)\n",
    "categorical_cols = df.select_dtypes(include='object').columns.tolist()\n",
    "for col in categorical_cols:\n",
    "    df[col] = df[col].astype(str)  # Convert to string if needed\n",
    "    df[col] = loaded_encoder.fit_transform(df[col])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4928e5ba",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- AccountName\n- AccountSid\n- AccountUpn\n- ApplicationId\n- ApplicationName\n- ...\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m X \u001b[38;5;241m=\u001b[39m X[trained_columns]  \u001b[38;5;66;03m# Reorder columns to match training\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Predict\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m dt_loaded\u001b[38;5;241m.\u001b[39mpredict(X)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\tree\\_classes.py:530\u001b[0m, in \u001b[0;36mBaseDecisionTree.predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    507\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Predict class or regression value for X.\u001b[39;00m\n\u001b[0;32m    508\u001b[0m \n\u001b[0;32m    509\u001b[0m \u001b[38;5;124;03mFor a classification model, the predicted class for each sample in X is\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    527\u001b[0m \u001b[38;5;124;03m    The predicted classes, or the predict values.\u001b[39;00m\n\u001b[0;32m    528\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    529\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 530\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_X_predict(X, check_input)\n\u001b[0;32m    531\u001b[0m proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_\u001b[38;5;241m.\u001b[39mpredict(X)\n\u001b[0;32m    532\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\tree\\_classes.py:489\u001b[0m, in \u001b[0;36mBaseDecisionTree._validate_X_predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    487\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    488\u001b[0m     ensure_all_finite \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 489\u001b[0m X \u001b[38;5;241m=\u001b[39m validate_data(\n\u001b[0;32m    490\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    491\u001b[0m     X,\n\u001b[0;32m    492\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mDTYPE,\n\u001b[0;32m    493\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    494\u001b[0m     reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    495\u001b[0m     ensure_all_finite\u001b[38;5;241m=\u001b[39mensure_all_finite,\n\u001b[0;32m    496\u001b[0m )\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[0;32m    498\u001b[0m     X\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc \u001b[38;5;129;01mor\u001b[39;00m X\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc\n\u001b[0;32m    499\u001b[0m ):\n\u001b[0;32m    500\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2919\u001b[0m, in \u001b[0;36mvalidate_data\u001b[1;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[0;32m   2835\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidate_data\u001b[39m(\n\u001b[0;32m   2836\u001b[0m     _estimator,\n\u001b[0;32m   2837\u001b[0m     \u001b[38;5;241m/\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2843\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[0;32m   2844\u001b[0m ):\n\u001b[0;32m   2845\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate input data and set or check feature names and counts of the input.\u001b[39;00m\n\u001b[0;32m   2846\u001b[0m \n\u001b[0;32m   2847\u001b[0m \u001b[38;5;124;03m    This helper function should be used in an estimator that requires input\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2917\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[0;32m   2918\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2919\u001b[0m     _check_feature_names(_estimator, X, reset\u001b[38;5;241m=\u001b[39mreset)\n\u001b[0;32m   2920\u001b[0m     tags \u001b[38;5;241m=\u001b[39m get_tags(_estimator)\n\u001b[0;32m   2921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m tags\u001b[38;5;241m.\u001b[39mtarget_tags\u001b[38;5;241m.\u001b[39mrequired:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2777\u001b[0m, in \u001b[0;36m_check_feature_names\u001b[1;34m(estimator, X, reset)\u001b[0m\n\u001b[0;32m   2774\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[0;32m   2775\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 2777\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[1;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- AccountName\n- AccountSid\n- AccountUpn\n- ApplicationId\n- ApplicationName\n- ...\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Load model\n",
    "with open('decision_tree_model.pkl', 'rb') as f:\n",
    "    dt_loaded = pickle.load(f)\n",
    "\n",
    "# Load feature names used during training\n",
    "with open('feature_columns.pkl', 'rb') as f:\n",
    "    trained_columns = pickle.load(f)\n",
    "\n",
    "# Prepare input data\n",
    "X = df.drop(columns=['IncidentGrade'])\n",
    "y = df['IncidentGrade']\n",
    "\n",
    "# Ensure same columns and order\n",
    "for col in trained_columns:\n",
    "    if col not in X.columns:\n",
    "        X[col] = 0  # or a sensible default\n",
    "\n",
    "X = X[trained_columns]  # Reorder columns to match training\n",
    "\n",
    "# Predict\n",
    "y_pred = dt_loaded.predict(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9852214c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before adjustment:\n",
      "Columns in X: ['Id', 'OrgId', 'IncidentId', 'AlertId', 'Timestamp', 'DetectorId', 'AlertTitle', 'Category', 'EntityType', 'EvidenceRole', 'DeviceId', 'Sha256', 'IpAddress', 'Url', 'AccountSid', 'AccountUpn', 'AccountObjectId', 'AccountName', 'DeviceName', 'NetworkMessageId', 'RegistryKey', 'RegistryValueName', 'RegistryValueData', 'ApplicationId', 'ApplicationName', 'OAuthApplicationId', 'FileName', 'FolderPath', 'ResourceIdName', 'OSFamily', 'OSVersion', 'CountryCode', 'State', 'City', 'Usage']\n",
      "After adjustment:\n",
      "Columns in X: ['Id', 'OrgId', 'IncidentId', 'AlertId', 'Timestamp', 'DetectorId', 'AlertTitle', 'Category', 'EntityType', 'EvidenceRole', 'DeviceId', 'Sha256', 'IpAddress', 'Url', 'AccountSid', 'AccountUpn', 'AccountObjectId', 'AccountName', 'DeviceName', 'NetworkMessageId', 'RegistryKey', 'RegistryValueName', 'RegistryValueData', 'ApplicationId', 'ApplicationName', 'OAuthApplicationId', 'FileName', 'FolderPath', 'ResourceIdName', 'OSFamily', 'OSVersion', 'CountryCode', 'State', 'City']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- AccountName\n- AccountSid\n- AccountUpn\n- ApplicationId\n- ApplicationName\n- ...\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumns in X:\u001b[39m\u001b[38;5;124m\"\u001b[39m, X\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mtolist())\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Predict\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m dt_loaded\u001b[38;5;241m.\u001b[39mpredict(X)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\tree\\_classes.py:530\u001b[0m, in \u001b[0;36mBaseDecisionTree.predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    507\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Predict class or regression value for X.\u001b[39;00m\n\u001b[0;32m    508\u001b[0m \n\u001b[0;32m    509\u001b[0m \u001b[38;5;124;03mFor a classification model, the predicted class for each sample in X is\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    527\u001b[0m \u001b[38;5;124;03m    The predicted classes, or the predict values.\u001b[39;00m\n\u001b[0;32m    528\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    529\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 530\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_X_predict(X, check_input)\n\u001b[0;32m    531\u001b[0m proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_\u001b[38;5;241m.\u001b[39mpredict(X)\n\u001b[0;32m    532\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\tree\\_classes.py:489\u001b[0m, in \u001b[0;36mBaseDecisionTree._validate_X_predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    487\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    488\u001b[0m     ensure_all_finite \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 489\u001b[0m X \u001b[38;5;241m=\u001b[39m validate_data(\n\u001b[0;32m    490\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    491\u001b[0m     X,\n\u001b[0;32m    492\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mDTYPE,\n\u001b[0;32m    493\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    494\u001b[0m     reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    495\u001b[0m     ensure_all_finite\u001b[38;5;241m=\u001b[39mensure_all_finite,\n\u001b[0;32m    496\u001b[0m )\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[0;32m    498\u001b[0m     X\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc \u001b[38;5;129;01mor\u001b[39;00m X\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc\n\u001b[0;32m    499\u001b[0m ):\n\u001b[0;32m    500\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2919\u001b[0m, in \u001b[0;36mvalidate_data\u001b[1;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[0;32m   2835\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidate_data\u001b[39m(\n\u001b[0;32m   2836\u001b[0m     _estimator,\n\u001b[0;32m   2837\u001b[0m     \u001b[38;5;241m/\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2843\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[0;32m   2844\u001b[0m ):\n\u001b[0;32m   2845\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate input data and set or check feature names and counts of the input.\u001b[39;00m\n\u001b[0;32m   2846\u001b[0m \n\u001b[0;32m   2847\u001b[0m \u001b[38;5;124;03m    This helper function should be used in an estimator that requires input\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2917\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[0;32m   2918\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2919\u001b[0m     _check_feature_names(_estimator, X, reset\u001b[38;5;241m=\u001b[39mreset)\n\u001b[0;32m   2920\u001b[0m     tags \u001b[38;5;241m=\u001b[39m get_tags(_estimator)\n\u001b[0;32m   2921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m tags\u001b[38;5;241m.\u001b[39mtarget_tags\u001b[38;5;241m.\u001b[39mrequired:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2777\u001b[0m, in \u001b[0;36m_check_feature_names\u001b[1;34m(estimator, X, reset)\u001b[0m\n\u001b[0;32m   2774\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[0;32m   2775\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 2777\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[1;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- AccountName\n- AccountSid\n- AccountUpn\n- ApplicationId\n- ApplicationName\n- ...\n"
     ]
    }
   ],
   "source": [
    "# Load trained columns\n",
    "with open('feature_columns.pkl', 'rb') as f:\n",
    "    trained_columns = pickle.load(f)\n",
    "\n",
    "X = df.drop(columns=['IncidentGrade'])\n",
    "y = df['IncidentGrade']\n",
    "\n",
    "print(\"Before adjustment:\")\n",
    "print(\"Columns in X:\", X.columns.tolist())\n",
    "\n",
    "# Add missing columns if any\n",
    "for col in trained_columns:\n",
    "    if col not in X.columns:\n",
    "        X[col] = 0\n",
    "\n",
    "# Remove extra columns\n",
    "X = X[trained_columns]\n",
    "\n",
    "print(\"After adjustment:\")\n",
    "print(\"Columns in X:\", X.columns.tolist())\n",
    "\n",
    "# Predict\n",
    "y_pred = dt_loaded.predict(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3af797a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "with open(\"label_encoder.pkl\", \"rb\") as f:\n",
    "    le = pickle.load(f)\n",
    "\n",
    "# # Step 1: Identify categorical columns\n",
    "categorical_cols = df.select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "# # Step 2: Initialize label encoder\n",
    "# le = LabelEncoder()\n",
    "\n",
    "# Step 3: Apply label encoding to each categorical column\n",
    "for col in categorical_cols:\n",
    "    df[col] = df[col].astype(str)  # Convert to string if needed\n",
    "    df[col] = le.fit_transform(df[col])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc82bb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Load model\n",
    "with open('decision_tree_model.pkl', 'rb') as f:\n",
    "    dt_loaded = pickle.load(f)\n",
    "\n",
    "# Load feature names used during training\n",
    "with open('feature_columns.pkl', 'rb') as f:\n",
    "    trained_columns = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02cad6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split features and target\n",
    "X = df.drop('IncidentGrade', axis=1)\n",
    "y = df['IncidentGrade']\n",
    "\n",
    "# Fit the model\n",
    "dt_loaded.fit(X, y)\n",
    "\n",
    "# Predict using the trained model\n",
    "y_pred =dt_loaded.predict(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c846a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00   1752940\n",
      "           1       1.00      1.00      1.00    902698\n",
      "           2       1.00      1.00      1.00   1492354\n",
      "\n",
      "    accuracy                           1.00   4147992\n",
      "   macro avg       1.00      1.00      1.00   4147992\n",
      "weighted avg       1.00      1.00      1.00   4147992\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1752940       0       0]\n",
      " [      0  902698       0]\n",
      " [      0       0 1492354]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y, y_pred))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e92e028",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
